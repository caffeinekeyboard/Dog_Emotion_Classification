{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of MoCov3 to detect dog emotions.\n",
    "- Batch Size : 128\n",
    "- Image resoltion : 224 X 224\n",
    "- Status : Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as torchvision_models\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moco.builder\n",
    "import moco.loader\n",
    "import moco.LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "RESOLUTION = 224\n",
    "DISTRIBUTED = False\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Generator.\n",
    "- Transforms yanked from the BYOL paper https://arxiv.org/abs/2006.07733."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation1 = [\n",
    "        transforms.RandomResizedCrop(RESOLUTION, scale=(0.8, 1.)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([moco.loader.GaussianBlur([.1, 2.])], p=1.0),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    "\n",
    "augmentation2 = [\n",
    "        transforms.RandomResizedCrop(RESOLUTION, scale=(0.8, 1.)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(0.4, 0.4, 0.2, 0.1)  # not strengthened\n",
    "        ], p=0.8),\n",
    "        transforms.RandomGrayscale(p=0.2),\n",
    "        transforms.RandomApply([moco.loader.GaussianBlur([.1, 2.])], p=0.1),\n",
    "        transforms.RandomApply([moco.loader.Solarize()], p=0.2),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.473, 0.440, 0.386],\n",
    "                                     std=[0.269, 0.260, 0.262])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindir = 'data/Daniel_Shan_Balico/train/'\n",
    "testdir = 'data/Daniel_Shan_Balico/test/'\n",
    "valdir = 'data/Daniel_Shan_Balico/val/'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "        traindir,\n",
    "        moco.loader.TwoCropsTransform(transforms.Compose(augmentation1), \n",
    "                                      transforms.Compose(augmentation2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ! Issue Faced ! If DISTRIBUTED = True, the following error occurs:  \n",
    "- Default process group has not been initialized, please make sure to call init_process_group.\n",
    "- SOLVED : Benched relevant code. (Would only need for multiple GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if DISTRIBUTED:\n",
    "#     train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "# else:\n",
    "#     train_sampler = None\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=BATCH_SIZE, shuffle = False,\n",
    "        num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Service Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "LEARNING_RATE = 1.5e-4\n",
    "WARMUP_EPOCHS = 40\n",
    "MOCO_MOMENTUM = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Decays the learning rate with half-cycle cosine after warmup\"\"\"\n",
    "    if epoch < WARMUP_EPOCHS:\n",
    "        lr = LEARNING_RATE * epoch / WARMUP_EPOCHS\n",
    "    else:\n",
    "        lr = LEARNING_RATE * 0.5 * (1. + math.cos(math.pi * (epoch - WARMUP_EPOCHS) / (EPOCHS - WARMUP_EPOCHS)))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "\n",
    "def adjust_moco_momentum(epoch):\n",
    "    \"\"\"Adjust moco momentum based on current epoch\"\"\"\n",
    "    m = 1. - 0.5 * (1. + math.cos(math.pi * epoch / EPOCHS)) * (1. - MOCO_MOMENTUM)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_l = enumerate(train_loader)\n",
    "a = next(train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Loop\n",
    "- 150 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GPU = 1\n",
    "MOCO_COS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, scaler, summary_writer, epoch, args):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    learning_rates = AverageMeter('LR', ':.4e')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, learning_rates, losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    iters_per_epoch = len(train_loader)\n",
    "    moco_m = args.moco_m\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # adjust learning rate and momentum coefficient per iteration\n",
    "        lr = adjust_learning_rate(optimizer, epoch + i / iters_per_epoch, args)\n",
    "        learning_rates.update(lr)\n",
    "        if MOCO_COS:\n",
    "            moco_m = adjust_moco_momentum(epoch + i / iters_per_epoch, args)\n",
    "\n",
    "        if NUM_GPU is not None:\n",
    "            images[0] = images[0].cuda(args.gpu, non_blocking=True)\n",
    "            images[1] = images[1].cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            loss = model(images[0], images[1], moco_m)\n",
    "\n",
    "        losses.update(loss.item(), images[0].size(0))\n",
    "        if args.rank == 0:\n",
    "            summary_writer.add_scalar(\"loss\", loss.item(), epoch * iters_per_epoch + i)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    pass\n",
    "    #Will require GPU manip and architecture of down-stream models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
