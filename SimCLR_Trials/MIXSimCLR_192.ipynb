{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil, time, os, requests, random, copy\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Daniel Shan Balico's dataset.\n",
    "- Carry out a train-validation split using sci-kit learn.\n",
    "- Reshape images to (3, 224, 224), flatten and load into 'trainimages', 'valimages' and 'testimages' array.\n",
    "- Subsequently store labels into 'trainlabels', 'valimages' and 'testlabels' array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4000 non-null   int64 \n",
      " 1   filename    4000 non-null   object\n",
      " 2   label       4000 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>yubL63eiiPmoRru8Z2K2yRo0NnGDCL683.jpg</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>c1tVljKiLM9q2zTBuQGWpxmzBuSeBR437.jpg</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RbzNOvY5GIAl3PSjIRTKpEkQs1NByq575.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>gKujaBuWYezz0yWK9ydTFVi6LbQtXe397.jpg</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>U0hJ2ryOu1IOuYpc01O7RngPYa8Xvz795.jpg</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                               filename    label\n",
       "0           0  yubL63eiiPmoRru8Z2K2yRo0NnGDCL683.jpg      sad\n",
       "1           1  c1tVljKiLM9q2zTBuQGWpxmzBuSeBR437.jpg      sad\n",
       "2           2  RbzNOvY5GIAl3PSjIRTKpEkQs1NByq575.jpg    angry\n",
       "3           3  gKujaBuWYezz0yWK9ydTFVi6LbQtXe397.jpg    angry\n",
       "4           4  U0hJ2ryOu1IOuYpc01O7RngPYa8Xvz795.jpg  relaxed"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('data/Daniel_Shan_Balico/labels.csv')\n",
    "dataframe.info()\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Stratified Shuffle Split on labels dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "for train_val_index, test_index in sss.split(dataframe, dataframe['label']):\n",
    "    train_val_set = dataframe.loc[train_val_index]\n",
    "    test_set = dataframe.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, val_index in sss.split(train_val_set, train_val_set['label']):\n",
    "    train_set = dataframe.loc[train_index]\n",
    "    val_set = dataframe.loc[val_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get graphings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "train_set['label'].hist()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "val_set['label'].hist()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "test_set['label'].hist()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Examples: 3240\n",
      "Validation Examples: 360\n",
      "Test Examples: 400\n"
     ]
    }
   ],
   "source": [
    "print('Train Examples:', train_set.shape[0])\n",
    "print('Validation Examples:', val_set.shape[0])\n",
    "print('Test Examples:', test_set.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feed the images into the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimages = np.array([], dtype=np.uint8).reshape((0, 3, 192, 192))\n",
    "valimages = np.array([], dtype=np.uint8).reshape((0, 3, 192, 192))\n",
    "testimages = np.array([], dtype=np.uint8).reshape((0, 3, 192, 192))\n",
    "trlabels = np.array([])\n",
    "vallabels = np.array([])\n",
    "testlabels = np.array([])\n",
    "\n",
    "label_dict = {'angry' : 0,\n",
    "              'happy' : 1,\n",
    "              'relaxed' : 2,\n",
    "              'sad' : 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3240/3240 [01:40<00:00, 32.15it/s]\n",
      "100%|██████████| 360/360 [00:01<00:00, 219.39it/s]\n",
      "100%|██████████| 400/400 [00:02<00:00, 197.36it/s]\n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(train_set.index):\n",
    "    img = Image.open('data/Daniel_Shan_Balico/all_images/' + train_set['filename'][index])\n",
    "    img = img.resize((192, 192))\n",
    "    img = np.asarray(img)\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = img.reshape(1, 3, 192, 192)\n",
    "    trimages = np.append(trimages, img, axis = 0)\n",
    "    trlabels = np.append(trlabels, label_dict[train_set['label'][index]])\n",
    "\n",
    "for index in tqdm(val_set.index):\n",
    "    img = Image.open('data/Daniel_Shan_Balico/all_images/' + val_set['filename'][index])\n",
    "    img = img.resize((192, 192))\n",
    "    img = np.asarray(img)\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = img.reshape(1, 3, 192, 192)\n",
    "    valimages = np.append(valimages, img, axis = 0)\n",
    "    vallabels = np.append(vallabels, label_dict[val_set['label'][index]])\n",
    "\n",
    "for index in tqdm(test_set.index):\n",
    "    img = Image.open('data/Daniel_Shan_Balico/all_images/' + test_set['filename'][index])\n",
    "    img = img.resize((192, 192))\n",
    "    img = np.asarray(img)\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = img.reshape(1, 3, 192, 192)\n",
    "    testimages = np.append(testimages, img, axis = 0)\n",
    "    testlabels = np.append(testlabels, label_dict[test_set['label'][index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/Daniel_Shan_Balico/numpy_arrays_192/trimages', trimages)\n",
    "np.save('data/Daniel_Shan_Balico/numpy_arrays_192/valimages', valimages)\n",
    "np.save('data/Daniel_Shan_Balico/numpy_arrays_192/testimages', testimages)\n",
    "np.save('data/Daniel_Shan_Balico/numpy_arrays_192/trlabels', trlabels)\n",
    "np.save('data/Daniel_Shan_Balico/numpy_arrays_192/vallabels', vallabels)\n",
    "np.save('data/Daniel_Shan_Balico/numpy_arrays_192/testlabels', testlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimages = np.load('data/Daniel_Shan_Balico/numpy_arrays_192/trimages.npy')\n",
    "valimages = np.load('data/Daniel_Shan_Balico/numpy_arrays_192/valimages.npy')\n",
    "testimages = np.load('data/Daniel_Shan_Balico/numpy_arrays_192/testimages.npy')\n",
    "trlabels = np.load('data/Daniel_Shan_Balico/numpy_arrays_192/trlabels.npy')\n",
    "vallabels = np.load('data/Daniel_Shan_Balico/numpy_arrays_192/vallabels.npy')\n",
    "testlabels = np.load('data/Daniel_Shan_Balico/numpy_arrays_192/testlabels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.47366378]]\n",
      "\n",
      "  [[0.44025252]]\n",
      "\n",
      "  [[0.38664348]]]]\n",
      "[[[[0.26858465]]\n",
      "\n",
      "  [[0.26024857]]\n",
      "\n",
      "  [[0.26190903]]]]\n"
     ]
    }
   ],
   "source": [
    "MEAN = np.mean(trimages/255.0,axis=(0,2,3),keepdims=True)\n",
    "STD = np.std(trimages/255.0,axis=(0,2,3),keepdims=True)\n",
    "print(MEAN)\n",
    "print(STD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data generator.\n",
    "- All augmentations performed as listed in the SimCLR paper https://arxiv.org/abs/2002.05709."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C10DataGen(Dataset):\n",
    "    def __init__(self,phase,imgarr,s = 0.5):\n",
    "        self.phase = phase\n",
    "        self.imgarr = imgarr\n",
    "        self.s = s\n",
    "        self.transforms = transforms.Compose([transforms.RandomHorizontalFlip(0.5),\n",
    "                                              transforms.RandomResizedCrop((192, 192),(0.8,1.0)),\n",
    "                                              transforms.Compose([transforms.RandomApply([transforms.ColorJitter(0.8*self.s, \n",
    "                                                                                                                 0.8*self.s, \n",
    "                                                                                                                 0.8*self.s, \n",
    "                                                                                                                 0.2*self.s)], p = 0.8),\n",
    "                                                                  transforms.RandomGrayscale(p=0.2)\n",
    "                                                                 ])])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.imgarr.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        x = self.imgarr[idx] \n",
    "        #print(x.shape)\n",
    "        x = x.astype(np.float32)/255.0\n",
    "\n",
    "        x1 = self.augment(torch.from_numpy(x))\n",
    "        x2 = self.augment(torch.from_numpy(x))\n",
    "        \n",
    "        x1 = self.preprocess(x1)\n",
    "        x2 = self.preprocess(x2)\n",
    "        \n",
    "        return x1, x2\n",
    "\n",
    "    #shuffles the dataset at the end of each epoch\n",
    "    def on_epoch_end(self):\n",
    "        self.imgarr = self.imgarr[random.sample(population = list(range(self.__len__())),k = self.__len__())]\n",
    "\n",
    "    def preprocess(self,frame):\n",
    "        frame = (frame-MEAN)/STD\n",
    "        return frame\n",
    "    \n",
    "    #applies randomly selected augmentations to each clip (same for each frame in the clip)\n",
    "    def augment(self, frame, transformations = None):\n",
    "        \n",
    "        if self.phase == 'train':\n",
    "            frame = self.transforms(frame)\n",
    "        else:\n",
    "            return frame\n",
    "        \n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = C10DataGen('train',trimages)\n",
    "dl = DataLoader(dg,batch_size = 128,drop_last=True)\n",
    "\n",
    "vdg = C10DataGen('valid',valimages)\n",
    "vdl = DataLoader(vdg,batch_size = 128,drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up model.\n",
    "- The Identity module gives output what it takes as input.\n",
    "- The LinearLayer module gives a single Linear layer followed by an optional BatchNormalization layer.\n",
    "- The ProjectionHead module gives a linear or non-linear projection head according to the argument passed.\n",
    "- The PreModel module gives the model to be used for pre-training, i.e. the base encoder f(.) with an MLP g(.) on top of it. \n",
    "- The class PreModel uses ResNet50. However, this can be modified according to your need and can even be made customizable with some little extra work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 use_bias = True,\n",
    "                 use_bn = False,\n",
    "                 **kwargs):\n",
    "        super(LinearLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = use_bias\n",
    "        self.use_bn = use_bn\n",
    "        \n",
    "        self.linear = nn.Linear(self.in_features, \n",
    "                                self.out_features, \n",
    "                                bias = self.use_bias and not self.use_bn)\n",
    "        if self.use_bn:\n",
    "             self.bn = nn.BatchNorm1d(self.out_features)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_features,\n",
    "                 out_features,\n",
    "                 head_type = 'nonlinear',\n",
    "                 **kwargs):\n",
    "        super(ProjectionHead,self).__init__(**kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.head_type = head_type\n",
    "\n",
    "        if self.head_type == 'linear':\n",
    "            self.layers = LinearLayer(self.in_features,self.out_features,False, True)\n",
    "        elif self.head_type == 'nonlinear':\n",
    "            self.layers = nn.Sequential(\n",
    "                LinearLayer(self.in_features,self.hidden_features,True, True),\n",
    "                nn.ReLU(),\n",
    "                LinearLayer(self.hidden_features,self.out_features,False,True))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class PreModel(nn.Module):\n",
    "    def __init__(self,base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        \n",
    "        #PRETRAINED MODEL\n",
    "        self.pretrained = models.resnet50(pretrained=True)\n",
    "        \n",
    "        self.pretrained.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
    "        self.pretrained.maxpool = Identity()\n",
    "        \n",
    "        self.pretrained.fc = Identity()\n",
    "        \n",
    "        for p in self.pretrained.parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "        self.projector = ProjectionHead(2048, 2048, 128)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.pretrained(x)\n",
    "        \n",
    "        xp = self.projector(torch.squeeze(out))\n",
    "        \n",
    "        return xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aarya/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/aarya/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = PreModel('resnet50').to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss Function.\n",
    "- The Loss function code has been taken from this repo (Spijkervet/SimCLR) and modified slightly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR_Loss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "\n",
    "        self.mask = self.mask_correlated_samples(batch_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size):\n",
    "        N = 2 * batch_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mask[i, batch_size + i] = 0\n",
    "            mask[batch_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "\n",
    "        N = 2 * self.batch_size\n",
    "\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
    "\n",
    "        sim_i_j = torch.diag(sim, self.batch_size)\n",
    "        sim_j_i = torch.diag(sim, -self.batch_size)\n",
    "        \n",
    "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
    "        negative_samples = sim[self.mask].reshape(N, -1)\n",
    "        \n",
    "        #SIMCLR\n",
    "        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(positive_samples.device).long() #.float()\n",
    "        \n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimizer.\n",
    "- LARS Optimizer as instructed in the SimCLR paper https://arxiv.org/abs/2002.05709.\n",
    "- Picked up from repo (Spijkervet/SimCLR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.optimizer import Optimizer, required\n",
    "import re\n",
    "\n",
    "EETA_DEFAULT = 0.001\n",
    "\n",
    "\n",
    "class LARS(Optimizer):\n",
    "    \"\"\"\n",
    "    Layer-wise Adaptive Rate Scaling for large batch training.\n",
    "    Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n",
    "    I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr=required,\n",
    "        momentum=0.9,\n",
    "        use_nesterov=False,\n",
    "        weight_decay=0.0,\n",
    "        exclude_from_weight_decay=None,\n",
    "        exclude_from_layer_adaptation=None,\n",
    "        classic_momentum=True,\n",
    "        eeta=EETA_DEFAULT,\n",
    "    ):\n",
    "        \"\"\"Constructs a LARSOptimizer.\n",
    "        Args:\n",
    "        lr: A `float` for learning rate.\n",
    "        momentum: A `float` for momentum.\n",
    "        use_nesterov: A 'Boolean' for whether to use nesterov momentum.\n",
    "        weight_decay: A `float` for weight decay.\n",
    "        exclude_from_weight_decay: A list of `string` for variable screening, if\n",
    "            any of the string appears in a variable's name, the variable will be\n",
    "            excluded for computing weight decay. For example, one could specify\n",
    "            the list like ['batch_normalization', 'bias'] to exclude BN and bias\n",
    "            from weight decay.\n",
    "        exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but\n",
    "            for layer adaptation. If it is None, it will be defaulted the same as\n",
    "            exclude_from_weight_decay.\n",
    "        classic_momentum: A `boolean` for whether to use classic (or popular)\n",
    "            momentum. The learning rate is applied during momeuntum update in\n",
    "            classic momentum, but after momentum for popular momentum.\n",
    "        eeta: A `float` for scaling of learning rate when computing trust ratio.\n",
    "        name: The name for the scope.\n",
    "        \"\"\"\n",
    "\n",
    "        self.epoch = 0\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            use_nesterov=use_nesterov,\n",
    "            weight_decay=weight_decay,\n",
    "            exclude_from_weight_decay=exclude_from_weight_decay,\n",
    "            exclude_from_layer_adaptation=exclude_from_layer_adaptation,\n",
    "            classic_momentum=classic_momentum,\n",
    "            eeta=eeta,\n",
    "        )\n",
    "\n",
    "        super(LARS, self).__init__(params, defaults)\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.weight_decay = weight_decay\n",
    "        self.use_nesterov = use_nesterov\n",
    "        self.classic_momentum = classic_momentum\n",
    "        self.eeta = eeta\n",
    "        self.exclude_from_weight_decay = exclude_from_weight_decay\n",
    "        # exclude_from_layer_adaptation is set to exclude_from_weight_decay if the\n",
    "        # arg is None.\n",
    "        if exclude_from_layer_adaptation:\n",
    "            self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
    "        else:\n",
    "            self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
    "\n",
    "    def step(self, epoch=None, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        if epoch is None:\n",
    "            epoch = self.epoch\n",
    "            self.epoch += 1\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group[\"weight_decay\"]\n",
    "            momentum = group[\"momentum\"]\n",
    "            eeta = group[\"eeta\"]\n",
    "            lr = group[\"lr\"]\n",
    "\n",
    "            for p in group[\"params\"]:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                param = p.data\n",
    "                grad = p.grad.data\n",
    "\n",
    "                param_state = self.state[p]\n",
    "\n",
    "                # TODO: get param names\n",
    "                # if self._use_weight_decay(param_name):\n",
    "                grad += self.weight_decay * param\n",
    "\n",
    "                if self.classic_momentum:\n",
    "                    trust_ratio = 1.0\n",
    "\n",
    "                    # TODO: get param names\n",
    "                    # if self._do_layer_adaptation(param_name):\n",
    "                    w_norm = torch.norm(param)\n",
    "                    g_norm = torch.norm(grad)\n",
    "\n",
    "                    device = g_norm.get_device()\n",
    "                    trust_ratio = torch.where(\n",
    "                        w_norm.gt(0),\n",
    "                        torch.where(\n",
    "                            g_norm.gt(0),\n",
    "                            (self.eeta * w_norm / g_norm),\n",
    "                            torch.Tensor([1.0]).to(device),\n",
    "                        ),\n",
    "                        torch.Tensor([1.0]).to(device),\n",
    "                    ).item()\n",
    "\n",
    "                    scaled_lr = lr * trust_ratio\n",
    "                    if \"momentum_buffer\" not in param_state:\n",
    "                        next_v = param_state[\"momentum_buffer\"] = torch.zeros_like(\n",
    "                            p.data\n",
    "                        )\n",
    "                    else:\n",
    "                        next_v = param_state[\"momentum_buffer\"]\n",
    "\n",
    "                    next_v.mul_(momentum).add_(scaled_lr, grad)\n",
    "                    if self.use_nesterov:\n",
    "                        update = (self.momentum * next_v) + (scaled_lr * grad)\n",
    "                    else:\n",
    "                        update = next_v\n",
    "\n",
    "                    p.data.add_(-update)\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _use_weight_decay(self, param_name):\n",
    "        \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
    "        if not self.weight_decay:\n",
    "            return False\n",
    "        if self.exclude_from_weight_decay:\n",
    "            for r in self.exclude_from_weight_decay:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def _do_layer_adaptation(self, param_name):\n",
    "        \"\"\"Whether to do layer-wise learning rate adaptation for `param_name`.\"\"\"\n",
    "        if self.exclude_from_layer_adaptation:\n",
    "            for r in self.exclude_from_layer_adaptation:\n",
    "                if re.search(r, param_name) is not None:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-02.\n",
      "Epoch 00000: adjusting learning rate of group 0 to 2.0000e-01.\n"
     ]
    }
   ],
   "source": [
    "#OPTMIZER\n",
    "optimizer = LARS(\n",
    "    [params for params in model.parameters() if params.requires_grad],\n",
    "    lr=0.2,\n",
    "    weight_decay=1e-6,\n",
    "    exclude_from_weight_decay=[\"batch_normalization\", \"bias\"],\n",
    ")\n",
    "\n",
    "# \"decay the learning rate with the cosine decay schedule without restarts\"\n",
    "#SCHEDULER OR LINEAR EWARMUP\n",
    "warmupscheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch : (epoch+1)/10.0, verbose = True)\n",
    "\n",
    "#SCHEDULER FOR COSINE DECAY\n",
    "mainscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, 500, eta_min=0.05, last_epoch=-1, verbose = True)\n",
    "\n",
    "#LOSS FUNCTION\n",
    "criterion = SimCLR_Loss(batch_size = 128, temperature = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, current_epoch, name):\n",
    "    out = os.path.join('/saved_models/',name.format(current_epoch))\n",
    "\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict':scheduler.state_dict()}, out)\n",
    "\n",
    "def plot_features(model, num_classes, num_feats, batch_size):\n",
    "    preds = np.array([]).reshape((0,1))\n",
    "    gt = np.array([]).reshape((0,1))\n",
    "    feats = np.array([]).reshape((0,num_feats))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x1,x2 in vdl:\n",
    "            x1 = x1.squeeze().to(device = 'cuda:0', dtype = torch.float)\n",
    "            out = model(x1)\n",
    "            out = out.cpu().data.numpy()#.reshape((1,-1))\n",
    "            feats = np.append(feats,out,axis = 0)\n",
    "    \n",
    "    tsne = TSNE(n_components = 2, perplexity = 50)\n",
    "    x_feats = tsne.fit_transform(feats)\n",
    "    num_samples = int(batch_size*(valimages.shape[0]//batch_size))#(len(val_df)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        plt.scatter(x_feats[vallabels[:num_samples]==i,1],x_feats[vallabels[:num_samples]==i,0])\n",
    "    \n",
    "    plt.legend([str(i) for i in range(num_classes)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10165"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100]\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aarya/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.41 GiB. GPU 0 has a total capacty of 7.79 GiB of which 759.62 MiB is free. Including non-PyTorch memory, this process has 7.03 GiB memory in use. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 24.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m x_j \u001b[38;5;241m=\u001b[39m x_j\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# positive pair, with encoding\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m z_i \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m z_j \u001b[38;5;241m=\u001b[39m model(x_j)\n\u001b[1;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(z_i, z_j)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 78\u001b[0m, in \u001b[0;36mPreModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m---> 78\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     xp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprojector(torch\u001b[38;5;241m.\u001b[39msqueeze(out))\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torchvision/models/resnet.py:154\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m    152\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m--> 154\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.41 GiB. GPU 0 has a total capacty of 7.79 GiB of which 759.62 MiB is free. Including non-PyTorch memory, this process has 7.03 GiB memory in use. Of the allocated memory 6.82 GiB is allocated by PyTorch, and 24.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "nr = 0\n",
    "current_epoch = 0\n",
    "epochs = 100\n",
    "tr_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(100):\n",
    "        \n",
    "    print(f\"Epoch [{epoch}/{epochs}]\\t\")\n",
    "    stime = time.time()\n",
    "\n",
    "    model.train()\n",
    "    tr_loss_epoch = 0\n",
    "    \n",
    "    for step, (x_i, x_j) in enumerate(dl):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.squeeze().to('cuda:0').float()\n",
    "        x_j = x_j.squeeze().to('cuda:0').float()\n",
    "\n",
    "        # positive pair, with encoding\n",
    "        z_i = model(x_i)\n",
    "        z_j = model(x_j)\n",
    "\n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        if nr == 0 and step % 50 == 0:\n",
    "            print(f\"Step [{step}/{len(dl)}]\\t Loss: {round(loss.item(), 5)}\")\n",
    "\n",
    "        tr_loss_epoch += loss.item()\n",
    "\n",
    "    if nr == 0 and epoch < 10:\n",
    "        warmupscheduler.step()\n",
    "    if nr == 0 and epoch >= 10:\n",
    "        mainscheduler.step()\n",
    "    \n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    if nr == 0 and (epoch+1) % 50 == 0:\n",
    "        save_model(model, optimizer, mainscheduler, current_epoch,\"SimCLR_CIFAR10_RN50_P128_LR0P2_LWup10_Cos500_T0p5_B128_checkpoint_{}_260621.pt\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss_epoch = 0\n",
    "        for step, (x_i, x_j) in enumerate(vdl):\n",
    "        \n",
    "          x_i = x_i.squeeze().to('cuda:0').float()\n",
    "          x_j = x_j.squeeze().to('cuda:0').float()\n",
    "\n",
    "          # positive pair, with encoding\n",
    "          z_i = model(x_i)\n",
    "          z_j = model(x_j)\n",
    "\n",
    "          loss = criterion(z_i, z_j)\n",
    "\n",
    "          if nr == 0 and step % 50 == 0:\n",
    "              print(f\"Step [{step}/{len(vdl)}]\\t Loss: {round(loss.item(),5)}\")\n",
    "\n",
    "          val_loss_epoch += loss.item()\n",
    "\n",
    "    if nr == 0:\n",
    "        tr_loss.append(tr_loss_epoch / len(dl))\n",
    "        val_loss.append(val_loss_epoch / len(vdl))\n",
    "        print(f\"Epoch [{epoch}/{epochs}]\\t Training Loss: {tr_loss_epoch / len(dl)}\\t lr: {round(lr, 5)}\")\n",
    "        print(f\"Epoch [{epoch}/{epochs}]\\t Validation Loss: {val_loss_epoch / len(vdl)}\\t lr: {round(lr, 5)}\")\n",
    "        current_epoch += 1\n",
    "\n",
    "    dg.on_epoch_end()\n",
    "\n",
    "    time_taken = (time.time()-stime)/60\n",
    "    print(f\"Epoch [{epoch}/{epochs}]\\t Time Taken: {time_taken} minutes\")\n",
    "\n",
    "    if (epoch+1)%10==0:\n",
    "        plot_features(model.pretrained, 4, 2048, 128)\n",
    "\n",
    "save_model(model, optimizer, mainscheduler, current_epoch, \"SimCLR_CIFAR10_RN50_P128_LR0P2_LWup10_Cos500_T0p5_B128_checkpoint_{}_260621.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
