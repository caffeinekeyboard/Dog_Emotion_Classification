{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from PIL import ImageFilter\n",
    "\n",
    "##############################################################################\n",
    "### Many parts of this are a modified version of the official MoCo code ######\n",
    "############### https://github.com/facebookresearch/moco #####################\n",
    "##############################################################################\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_metric_learning import losses\n",
    "from pytorch_metric_learning.utils import logging_presets\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "class TwoCropsTransform:\n",
    "    \"\"\"Take two random crops of one image as the query and key.\"\"\"\n",
    "\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        q = self.base_transform(x)\n",
    "        k = self.base_transform(x)\n",
    "        return [q, k]\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[0.1, 2.0]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        return x\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "def create_dataset(batch_size):\n",
    "    normalize = transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010])\n",
    "\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(32),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply([transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_transform = TwoCropsTransform(train_transform)\n",
    "\n",
    "    val_transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        \"data/Daniel_Shan_Balico/train/\", transform=train_transform\n",
    "    )\n",
    "    train_dataset_for_eval = datasets.ImageFolder(\n",
    "        \"data/Daniel_Shan_Balico/validation/\", transform=val_transform\n",
    "    )\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        \"data/Daniel_Shan_Balico/test/\", transform=val_transform\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    train_loader_for_eval = torch.utils.data.DataLoader(\n",
    "        train_dataset_for_eval,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train_dataset,\n",
    "        train_dataset_for_eval,\n",
    "        val_dataset,\n",
    "        train_loader,\n",
    "        train_loader_for_eval,\n",
    "        val_loader,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    train_dataset,\n",
    "    train_dataset_for_eval,\n",
    "    val_dataset,\n",
    "    train_loader,\n",
    "    train_loader_for_eval,\n",
    "    val_loader,\n",
    ") = create_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = enumerate(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " [[tensor([[[[-7.6196e-01, -1.8475e+00, -1.0721e+00,  ...,  8.4699e-01,\n",
       "              -6.4106e-02, -1.0721e+00],\n",
       "             [-7.2319e-01, -1.7118e+00, -1.2660e+00,  ...,  2.4605e-01,\n",
       "              -1.1303e+00, -1.3629e+00],\n",
       "             [-5.8750e-01, -1.1497e+00, -1.4211e+00,  ..., -8.2012e-01,\n",
       "              -1.6343e+00, -1.2854e+00],\n",
       "             ...,\n",
       "             [-2.4291e+00, -2.4291e+00, -1.8669e+00,  ...,  6.1437e-01,\n",
       "              -6.6504e-01, -1.4792e+00],\n",
       "             [-2.3903e+00, -2.4291e+00, -2.0801e+00,  ...,  3.6236e-01,\n",
       "              -1.1690e+00, -1.5374e+00],\n",
       "             [-2.4291e+00, -2.4291e+00, -2.0801e+00,  ...,  2.4605e-01,\n",
       "              -1.4017e+00, -1.4986e+00]],\n",
       "   \n",
       "            [[-2.0446e+00, -2.3199e+00, -1.7299e+00,  ..., -2.2413e+00,\n",
       "              -2.1036e+00, -2.1823e+00],\n",
       "             [-1.9266e+00, -2.2609e+00, -1.9069e+00,  ..., -2.1036e+00,\n",
       "              -2.3199e+00, -2.2806e+00],\n",
       "             [-1.9659e+00, -1.9856e+00, -2.0053e+00,  ..., -2.2216e+00,\n",
       "              -2.4183e+00, -2.2413e+00],\n",
       "             ...,\n",
       "             [-2.2216e+00, -2.4183e+00, -2.1626e+00,  ..., -7.4657e-01,\n",
       "              -1.4349e+00, -1.3759e+00],\n",
       "             [-2.2019e+00, -2.4183e+00, -2.2806e+00,  ..., -1.1596e+00,\n",
       "              -1.6316e+00, -1.3169e+00],\n",
       "             [-2.2216e+00, -2.4183e+00, -2.2609e+00,  ..., -1.2382e+00,\n",
       "              -1.8086e+00, -1.3169e+00]],\n",
       "   \n",
       "            [[-1.9287e+00, -2.2214e+00, -1.8312e+00,  ..., -4.2645e-01,\n",
       "              -1.4215e+00, -2.2214e+00],\n",
       "             [-1.8312e+00, -2.2214e+00, -1.9678e+00,  ..., -1.0508e+00,\n",
       "              -2.2214e+00, -2.2214e+00],\n",
       "             [-1.8117e+00, -2.1238e+00, -2.0068e+00,  ..., -2.0653e+00,\n",
       "              -2.2214e+00, -2.2214e+00],\n",
       "             ...,\n",
       "             [-1.7141e+00, -2.1434e+00, -2.0653e+00,  ..., -1.3629e+00,\n",
       "              -1.4410e+00, -7.5812e-01],\n",
       "             [-1.6361e+00, -2.1238e+00, -2.1238e+00,  ..., -1.6556e+00,\n",
       "              -1.4215e+00, -6.8008e-01],\n",
       "             [-1.6556e+00, -2.1238e+00, -2.1434e+00,  ..., -1.7336e+00,\n",
       "              -1.5190e+00, -6.6057e-01]]],\n",
       "   \n",
       "   \n",
       "           [[[ 7.8883e-01,  7.6945e-01,  8.2760e-01,  ..., -6.4106e-02,\n",
       "               3.2359e-01,  3.0421e-01],\n",
       "             [ 4.3990e-01,  3.8175e-01,  5.1744e-01,  ..., -1.0288e-01,\n",
       "               2.6544e-01,  2.0728e-01],\n",
       "             [ 3.4298e-01,  3.6236e-01,  5.5621e-01,  ..., -1.2226e-01,\n",
       "               3.0421e-01,  3.0421e-01],\n",
       "             ...,\n",
       "             [ 5.5621e-01,  5.3683e-01,  4.5929e-01,  ...,  4.5929e-01,\n",
       "               5.1744e-01,  3.8175e-01],\n",
       "             [ 6.7252e-01,  5.1744e-01,  5.1744e-01,  ...,  4.2052e-01,\n",
       "               5.3683e-01,  5.1744e-01],\n",
       "             [ 4.9806e-01,  3.4298e-01,  4.9806e-01,  ...,  3.6236e-01,\n",
       "               3.0421e-01,  3.6236e-01]],\n",
       "   \n",
       "            [[ 7.2844e-01,  6.8911e-01,  7.4811e-01,  ..., -3.8567e-02,\n",
       "               3.1544e-01,  2.7610e-01],\n",
       "             [ 3.5477e-01,  2.7610e-01,  4.9244e-01,  ..., -9.7567e-02,\n",
       "               2.7610e-01,  2.5644e-01],\n",
       "             [ 2.7610e-01,  2.7610e-01,  5.1211e-01,  ..., -9.7567e-02,\n",
       "               2.3677e-01,  2.3677e-01],\n",
       "             ...,\n",
       "             [ 3.3510e-01,  3.5477e-01,  2.7610e-01,  ...,  3.9410e-01,\n",
       "               4.1377e-01,  3.1544e-01],\n",
       "             [ 5.1211e-01,  3.7444e-01,  3.5477e-01,  ...,  4.1377e-01,\n",
       "               5.1211e-01,  5.3177e-01],\n",
       "             [ 4.7277e-01,  3.3510e-01,  5.1211e-01,  ...,  4.1377e-01,\n",
       "               3.5477e-01,  4.9244e-01]],\n",
       "   \n",
       "            [[ 9.0025e-01,  8.6123e-01,  9.7829e-01,  ...,  1.9788e-01,\n",
       "               5.2956e-01,  4.1250e-01],\n",
       "             [ 5.4907e-01,  4.7103e-01,  7.2466e-01,  ...,  1.3935e-01,\n",
       "               3.9299e-01,  2.9543e-01],\n",
       "             [ 5.2956e-01,  5.2956e-01,  7.4417e-01,  ...,  1.1984e-01,\n",
       "               3.7348e-01,  3.9299e-01],\n",
       "             ...,\n",
       "             [ 6.0760e-01,  6.0760e-01,  4.9054e-01,  ...,  4.9054e-01,\n",
       "               5.4907e-01,  4.1250e-01],\n",
       "             [ 6.8564e-01,  4.9054e-01,  4.7103e-01,  ...,  3.9299e-01,\n",
       "               6.4662e-01,  5.2956e-01],\n",
       "             [ 5.2956e-01,  3.1495e-01,  4.5152e-01,  ...,  3.9299e-01,\n",
       "               2.9543e-01,  4.5152e-01]]],\n",
       "   \n",
       "   \n",
       "           [[[-7.6196e-01, -5.4873e-01, -6.2627e-01,  ..., -8.0073e-01,\n",
       "              -7.4258e-01, -7.0381e-01],\n",
       "             [-8.3950e-01, -7.6196e-01, -6.6504e-01,  ..., -8.3950e-01,\n",
       "              -8.0073e-01, -8.0073e-01],\n",
       "             [-6.6504e-01, -6.2627e-01, -5.6811e-01,  ..., -9.7520e-01,\n",
       "              -9.3643e-01, -8.9766e-01],\n",
       "             ...,\n",
       "             [-1.3241e+00, -1.2078e+00, -9.1704e-01,  ..., -9.7520e-01,\n",
       "              -9.9458e-01, -1.1497e+00],\n",
       "             [-1.3241e+00, -1.2272e+00, -1.0140e+00,  ..., -9.7520e-01,\n",
       "              -1.0721e+00, -1.1109e+00],\n",
       "             [-1.3435e+00, -1.2660e+00, -1.1497e+00,  ..., -1.0140e+00,\n",
       "              -1.1109e+00, -1.1884e+00]],\n",
       "   \n",
       "            [[-7.2691e-01, -5.1057e-01, -5.8924e-01,  ..., -7.6624e-01,\n",
       "              -7.0724e-01, -6.6791e-01],\n",
       "             [-8.0557e-01, -7.2691e-01, -6.2857e-01,  ..., -8.0557e-01,\n",
       "              -7.6624e-01, -7.6624e-01],\n",
       "             [-6.2857e-01, -5.8924e-01, -5.3024e-01,  ..., -9.4324e-01,\n",
       "              -9.0391e-01, -8.6457e-01],\n",
       "             ...,\n",
       "             [-1.2972e+00, -1.1792e+00, -8.8424e-01,  ..., -9.4324e-01,\n",
       "              -9.6291e-01, -1.1202e+00],\n",
       "             [-1.2972e+00, -1.1989e+00, -9.8258e-01,  ..., -9.4324e-01,\n",
       "              -1.0416e+00, -1.0809e+00],\n",
       "             [-1.3169e+00, -1.2382e+00, -1.1202e+00,  ..., -9.8258e-01,\n",
       "              -1.0809e+00, -1.1596e+00]],\n",
       "   \n",
       "            [[-5.4351e-01, -3.2889e-01, -4.0694e-01,  ..., -5.8253e-01,\n",
       "              -5.2400e-01, -4.8498e-01],\n",
       "             [-6.2155e-01, -5.4351e-01, -4.4596e-01,  ..., -6.2155e-01,\n",
       "              -5.8253e-01, -5.8253e-01],\n",
       "             [-4.4596e-01, -4.0694e-01, -3.4841e-01,  ..., -7.5812e-01,\n",
       "              -7.1910e-01, -6.8008e-01],\n",
       "             ...,\n",
       "             [-1.1093e+00, -9.9224e-01, -6.9959e-01,  ..., -7.5812e-01,\n",
       "              -7.7763e-01, -9.3371e-01],\n",
       "             [-1.1093e+00, -1.0118e+00, -7.9714e-01,  ..., -7.5812e-01,\n",
       "              -8.5567e-01, -8.9469e-01],\n",
       "             [-1.1288e+00, -1.0508e+00, -9.3371e-01,  ..., -7.9714e-01,\n",
       "              -8.9469e-01, -9.7273e-01]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[-6.4565e-01, -1.0915e+00, -8.9766e-01,  ...,  9.6329e-01,\n",
       "               4.7867e-01,  9.0514e-01],\n",
       "             [-3.7426e-01, -6.6504e-01, -5.4873e-01,  ...,  7.3068e-01,\n",
       "               4.0113e-01,  8.6637e-01],\n",
       "             [-2.9672e-01, -5.4873e-01,  2.0728e-01,  ...,  7.3068e-01,\n",
       "               4.0113e-01,  7.5006e-01],\n",
       "             ...,\n",
       "             [-3.3549e-01, -4.7119e-01, -4.1303e-01,  ...,  3.2819e-02,\n",
       "               3.6236e-01,  4.9806e-01],\n",
       "             [-6.2627e-01, -2.9672e-01, -2.7734e-01,  ..., -1.2226e-01,\n",
       "               3.2819e-02,  3.6236e-01],\n",
       "             [-4.9057e-01, -6.4106e-02, -4.4721e-02,  ..., -5.2934e-01,\n",
       "              -1.0288e-01,  2.4605e-01]],\n",
       "   \n",
       "            [[-8.0557e-01, -1.1989e+00, -7.6624e-01,  ...,  4.9244e-01,\n",
       "              -3.8567e-02,  5.7111e-01],\n",
       "             [-5.4990e-01, -8.2524e-01, -6.4824e-01,  ...,  2.5644e-01,\n",
       "              -9.7567e-02,  5.3177e-01],\n",
       "             [-4.5157e-01, -7.0724e-01,  2.0434e-02,  ...,  2.3677e-01,\n",
       "              -7.7900e-02,  3.9410e-01],\n",
       "             ...,\n",
       "             [-5.4990e-01, -6.8757e-01, -6.8757e-01,  ..., -2.7457e-01,\n",
       "               5.9768e-02,  2.1710e-01],\n",
       "             [-8.4491e-01, -5.3024e-01, -5.3024e-01,  ..., -4.5157e-01,\n",
       "              -2.7457e-01,  2.0434e-02],\n",
       "             [-7.2691e-01, -2.9424e-01, -3.5324e-01,  ..., -6.8757e-01,\n",
       "              -2.9424e-01, -5.8233e-02]],\n",
       "   \n",
       "            [[-8.1665e-01, -9.9224e-01, -4.4596e-01,  ...,  2.2291e-02,\n",
       "              -4.8498e-01,  1.0033e-01],\n",
       "             [-5.2400e-01, -8.1665e-01, -5.4351e-01,  ..., -2.3134e-01,\n",
       "              -5.2400e-01,  6.1311e-02],\n",
       "             [-4.4596e-01, -8.5567e-01, -3.0938e-01,  ..., -2.3134e-01,\n",
       "              -5.2400e-01, -5.5751e-02],\n",
       "             ...,\n",
       "             [-7.9714e-01, -9.3371e-01, -8.9469e-01,  ..., -4.4596e-01,\n",
       "              -2.3134e-01, -1.1428e-01],\n",
       "             [-1.0703e+00, -7.7763e-01, -7.7763e-01,  ..., -6.0204e-01,\n",
       "              -4.8498e-01, -2.5085e-01],\n",
       "             [-9.7273e-01, -5.2400e-01, -5.2400e-01,  ..., -7.9714e-01,\n",
       "              -4.8498e-01, -2.5085e-01]]],\n",
       "   \n",
       "   \n",
       "           [[[ 1.6851e-01,  1.6851e-01,  1.8790e-01,  ...,  3.0421e-01,\n",
       "               4.3990e-01,  5.7560e-01],\n",
       "             [ 1.6851e-01,  1.6851e-01,  9.0974e-02,  ...,  4.9806e-01,\n",
       "               6.1437e-01,  6.5314e-01],\n",
       "             [ 1.4913e-01,  1.6851e-01,  1.6851e-01,  ...,  4.7867e-01,\n",
       "               5.1744e-01,  4.7867e-01],\n",
       "             ...,\n",
       "             [-3.7426e-01, -3.3549e-01, -2.1919e-01,  ...,  7.5006e-01,\n",
       "               7.8883e-01,  8.2760e-01],\n",
       "             [-5.2934e-01, -4.9057e-01, -2.7734e-01,  ...,  7.5006e-01,\n",
       "               8.0822e-01,  9.0514e-01],\n",
       "             [-6.6504e-01, -5.8750e-01, -3.3549e-01,  ...,  9.2452e-01,\n",
       "               8.4699e-01,  8.6637e-01]],\n",
       "   \n",
       "            [[ 1.9744e-01,  2.1710e-01,  2.7610e-01,  ...,  3.3510e-01,\n",
       "               4.5310e-01,  5.9077e-01],\n",
       "             [ 1.9744e-01,  2.1710e-01,  1.3844e-01,  ...,  4.3344e-01,\n",
       "               6.3011e-01,  7.0877e-01],\n",
       "             [ 1.9744e-01,  2.1710e-01,  2.1710e-01,  ...,  5.1211e-01,\n",
       "               5.3177e-01,  5.1211e-01],\n",
       "             ...,\n",
       "             [-1.7692e+00, -1.8282e+00, -1.8676e+00,  ..., -1.0022e+00,\n",
       "              -1.0022e+00, -1.0809e+00],\n",
       "             [-1.8282e+00, -1.8873e+00, -1.8479e+00,  ..., -1.2382e+00,\n",
       "              -1.1989e+00, -1.1006e+00],\n",
       "             [-1.8676e+00, -1.9266e+00, -1.8479e+00,  ..., -1.1596e+00,\n",
       "              -1.3366e+00, -1.1006e+00]],\n",
       "   \n",
       "            [[ 3.3446e-01,  3.9299e-01,  5.4907e-01,  ...,  4.5152e-01,\n",
       "               5.8809e-01,  6.2711e-01],\n",
       "             [ 3.3446e-01,  3.9299e-01,  3.9299e-01,  ...,  5.8809e-01,\n",
       "               7.4417e-01,  6.8564e-01],\n",
       "             [ 3.7348e-01,  3.9299e-01,  3.9299e-01,  ...,  6.4662e-01,\n",
       "               6.6613e-01,  5.6858e-01],\n",
       "             ...,\n",
       "             [-1.5776e+00, -1.7141e+00, -1.7531e+00,  ..., -9.5322e-01,\n",
       "              -8.5567e-01, -1.0118e+00],\n",
       "             [-1.6361e+00, -1.7531e+00, -1.7727e+00,  ..., -1.1873e+00,\n",
       "              -1.1288e+00, -1.0118e+00],\n",
       "             [-1.6751e+00, -1.7727e+00, -1.7727e+00,  ..., -1.1873e+00,\n",
       "              -1.3434e+00, -1.0313e+00]]],\n",
       "   \n",
       "   \n",
       "           [[[ 2.6544e-01,  1.2974e-01,  1.2974e-01,  ...,  5.5621e-01,\n",
       "               5.1744e-01,  3.4298e-01],\n",
       "             [ 1.3434e-02,  5.2204e-02,  2.2667e-01,  ...,  4.7867e-01,\n",
       "               4.7867e-01,  3.8175e-01],\n",
       "             [ 1.1036e-01,  3.6236e-01,  6.7252e-01,  ...,  5.3683e-01,\n",
       "               5.1744e-01,  4.5929e-01],\n",
       "             ...,\n",
       "             [ 1.3510e+00,  1.1959e+00,  1.1765e+00,  ...,  5.9498e-01,\n",
       "               2.0728e-01, -2.3857e-01],\n",
       "             [ 2.0489e+00,  1.9519e+00,  1.8744e+00,  ...,  1.6030e+00,\n",
       "               1.4285e+00,  1.1184e+00],\n",
       "             [ 2.2039e+00,  2.2039e+00,  2.1458e+00,  ...,  2.1070e+00,\n",
       "               2.1070e+00,  1.9519e+00]],\n",
       "   \n",
       "            [[ 3.1544e-01,  1.9744e-01,  1.3844e-01,  ...,  2.3677e-01,\n",
       "               1.7777e-01,  4.0101e-02],\n",
       "             [-3.8567e-02,  7.6703e-04,  5.9768e-02,  ...,  2.5644e-01,\n",
       "               3.1544e-01,  2.3677e-01],\n",
       "             [-3.8567e-02,  1.5810e-01,  3.3510e-01,  ...,  3.7444e-01,\n",
       "               4.3344e-01,  4.3344e-01],\n",
       "             ...,\n",
       "             [ 7.6777e-01,  6.3011e-01,  6.3011e-01,  ...,  4.0101e-02,\n",
       "              -2.1557e-01, -5.3024e-01],\n",
       "             [ 1.2988e+00,  1.2398e+00,  1.2004e+00,  ...,  8.0711e-01,\n",
       "               6.6944e-01,  4.9244e-01],\n",
       "             [ 1.5348e+00,  1.4954e+00,  1.4364e+00,  ...,  1.2988e+00,\n",
       "               1.2988e+00,  1.1808e+00]],\n",
       "   \n",
       "            [[ 8.0821e-02, -5.5751e-02, -2.3134e-01,  ..., -5.5751e-02,\n",
       "               4.1801e-02, -1.5330e-01],\n",
       "             [-4.2645e-01, -4.4596e-01, -4.0694e-01,  ...,  1.1984e-01,\n",
       "               2.9543e-01,  1.9788e-01],\n",
       "             [-5.6302e-01, -4.4596e-01, -3.6792e-01,  ...,  3.9299e-01,\n",
       "               6.8564e-01,  7.2466e-01],\n",
       "             ...,\n",
       "             [-1.9232e-01, -3.4841e-01, -4.2645e-01,  ..., -7.5812e-01,\n",
       "              -9.3371e-01, -1.1678e+00],\n",
       "             [ 3.5397e-01,  3.5397e-01,  2.5641e-01,  ..., -9.4771e-02,\n",
       "              -2.1183e-01, -3.6792e-01],\n",
       "             [ 5.2956e-01,  6.0760e-01,  5.1005e-01,  ...,  2.9543e-01,\n",
       "               2.7592e-01,  1.7837e-01]]]]),\n",
       "   tensor([[[[-4.1303e-01, -4.5180e-01, -2.5336e-02,  ...,  1.2928e+00,\n",
       "               4.7867e-01, -8.3491e-02],\n",
       "             [-4.1303e-01, -5.4873e-01, -4.5180e-01,  ...,  7.3068e-01,\n",
       "              -3.3549e-01, -8.5889e-01],\n",
       "             [-3.1611e-01, -2.7734e-01,  7.1589e-02,  ...,  3.4298e-01,\n",
       "              -6.0688e-01, -1.5180e+00],\n",
       "             ...,\n",
       "             [-2.4291e+00, -2.4291e+00, -2.1771e+00,  ..., -8.2012e-01,\n",
       "              -4.9057e-01, -8.3491e-02],\n",
       "             [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ...,  1.1036e-01,\n",
       "              -4.4721e-02, -1.8042e-01],\n",
       "             [-2.4291e+00, -2.4291e+00, -2.4291e+00,  ..., -1.2226e-01,\n",
       "              -4.7119e-01, -5.0996e-01]],\n",
       "   \n",
       "            [[-2.0839e+00, -1.9856e+00, -1.3759e+00,  ...,  4.5310e-01,\n",
       "              -1.9590e-01, -5.1057e-01],\n",
       "             [-2.1626e+00, -2.2019e+00, -1.9659e+00,  ..., -1.3690e-01,\n",
       "              -9.4324e-01, -1.3956e+00],\n",
       "             [-1.7299e+00, -1.7496e+00, -1.5332e+00,  ..., -4.5157e-01,\n",
       "              -1.1596e+00, -1.7102e+00],\n",
       "             ...,\n",
       "             [-2.4183e+00, -2.4183e+00, -1.9659e+00,  ..., -5.6957e-01,\n",
       "              -2.1557e-01,  1.7777e-01],\n",
       "             [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ...,  1.3844e-01,\n",
       "              -1.5657e-01, -4.7124e-01],\n",
       "             [-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -8.2524e-01,\n",
       "              -1.3562e+00, -1.4349e+00]],\n",
       "   \n",
       "            [[-1.7531e+00, -1.5971e+00, -1.2849e+00,  ...,  5.1005e-01,\n",
       "              -5.5751e-02, -2.3134e-01],\n",
       "             [-1.7922e+00, -1.7727e+00, -1.6751e+00,  ...,  2.2291e-02,\n",
       "              -7.9714e-01, -1.1873e+00],\n",
       "             [-1.4020e+00, -1.3825e+00, -1.3434e+00,  ..., -2.8987e-01,\n",
       "              -9.9224e-01, -1.4800e+00],\n",
       "             ...,\n",
       "             [-2.2214e+00, -2.2214e+00, -1.6751e+00,  ..., -2.8987e-01,\n",
       "               1.3935e-01,  5.2956e-01],\n",
       "             [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ...,  4.1250e-01,\n",
       "               8.0821e-02, -2.8987e-01],\n",
       "             [-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -7.1910e-01,\n",
       "              -1.2264e+00, -1.3825e+00]]],\n",
       "   \n",
       "   \n",
       "           [[[ 4.7867e-01,  3.0421e-01,  2.8482e-01,  ...,  3.2359e-01,\n",
       "               2.0728e-01,  2.6544e-01],\n",
       "             [ 5.7560e-01,  4.7867e-01,  4.0113e-01,  ...,  3.2359e-01,\n",
       "               3.4298e-01,  4.2052e-01],\n",
       "             [ 5.3683e-01,  4.9806e-01,  4.7867e-01,  ...,  3.0421e-01,\n",
       "               4.3990e-01,  4.3990e-01],\n",
       "             ...,\n",
       "             [ 8.0822e-01,  7.8883e-01,  8.0822e-01,  ...,  2.2667e-01,\n",
       "               1.4913e-01,  1.8790e-01],\n",
       "             [ 6.9191e-01,  6.9191e-01,  6.1437e-01,  ...,  3.4298e-01,\n",
       "               3.6236e-01,  2.6544e-01],\n",
       "             [ 6.3375e-01,  5.7560e-01,  4.2052e-01,  ...,  3.8175e-01,\n",
       "               2.0728e-01,  2.8482e-01]],\n",
       "   \n",
       "            [[ 5.1211e-01,  3.3510e-01,  3.1544e-01,  ...,  3.7444e-01,\n",
       "               3.1544e-01,  3.7444e-01],\n",
       "             [ 5.3177e-01,  4.3344e-01,  3.7444e-01,  ...,  3.7444e-01,\n",
       "               3.7444e-01,  4.7277e-01],\n",
       "             [ 4.7277e-01,  4.5310e-01,  4.9244e-01,  ...,  3.5477e-01,\n",
       "               4.5310e-01,  4.7277e-01],\n",
       "             ...,\n",
       "             [ 8.2677e-01,  8.0711e-01,  8.2677e-01,  ...,  3.7444e-01,\n",
       "               4.1377e-01,  4.3344e-01],\n",
       "             [ 7.6777e-01,  7.6777e-01,  6.8911e-01,  ...,  4.9244e-01,\n",
       "               4.5310e-01,  4.3344e-01],\n",
       "             [ 6.8911e-01,  6.3011e-01,  5.3177e-01,  ...,  5.9077e-01,\n",
       "               3.5477e-01,  5.5144e-01]],\n",
       "   \n",
       "            [[ 7.0515e-01,  5.2956e-01,  5.1005e-01,  ...,  4.7103e-01,\n",
       "               3.7348e-01,  4.1250e-01],\n",
       "             [ 7.6368e-01,  6.4662e-01,  5.8809e-01,  ...,  4.3201e-01,\n",
       "               4.9054e-01,  5.8809e-01],\n",
       "             [ 6.6613e-01,  6.0760e-01,  6.2711e-01,  ...,  4.1250e-01,\n",
       "               5.6858e-01,  6.0760e-01],\n",
       "             ...,\n",
       "             [ 8.8074e-01,  8.6123e-01,  8.6123e-01,  ...,  1.9788e-01,\n",
       "               2.1739e-01,  3.3446e-01],\n",
       "             [ 7.0515e-01,  7.2466e-01,  6.2711e-01,  ...,  3.5397e-01,\n",
       "               3.9299e-01,  3.7348e-01],\n",
       "             [ 7.2466e-01,  6.2711e-01,  4.7103e-01,  ...,  5.1005e-01,\n",
       "               2.9543e-01,  5.1005e-01]]],\n",
       "   \n",
       "   \n",
       "           [[[-1.0288e-01, -2.1919e-01, -3.7426e-01,  ..., -1.7894e+00,\n",
       "              -1.5567e+00, -1.4404e+00],\n",
       "             [-3.5488e-01, -7.2319e-01, -1.1303e+00,  ..., -1.8087e+00,\n",
       "              -1.6343e+00, -1.4211e+00],\n",
       "             [-9.5581e-01, -1.4986e+00, -1.7700e+00,  ..., -1.7118e+00,\n",
       "              -1.6343e+00, -1.3435e+00],\n",
       "             ...,\n",
       "             [ 1.3122e+00,  1.3122e+00,  1.2928e+00,  ...,  1.3316e+00,\n",
       "               1.2928e+00,  1.2735e+00],\n",
       "             [ 1.2347e+00,  1.1571e+00,  1.1378e+00,  ...,  1.1959e+00,\n",
       "               1.1959e+00,  1.1959e+00],\n",
       "             [ 1.2541e+00,  1.1765e+00,  1.2347e+00,  ...,  1.1571e+00,\n",
       "               1.1959e+00,  1.1571e+00]],\n",
       "   \n",
       "            [[-5.8233e-02, -1.7623e-01, -3.3357e-01,  ..., -1.7692e+00,\n",
       "              -1.5332e+00, -1.4152e+00],\n",
       "             [-3.1390e-01, -6.8757e-01, -1.1006e+00,  ..., -1.7889e+00,\n",
       "              -1.6119e+00, -1.3956e+00],\n",
       "             [-9.2357e-01, -1.4742e+00, -1.7496e+00,  ..., -1.6906e+00,\n",
       "              -1.6119e+00, -1.3169e+00],\n",
       "             ...,\n",
       "             [ 1.3774e+00,  1.3774e+00,  1.3578e+00,  ...,  1.3971e+00,\n",
       "               1.3578e+00,  1.3381e+00],\n",
       "             [ 1.2988e+00,  1.2201e+00,  1.2004e+00,  ...,  1.2594e+00,\n",
       "               1.2594e+00,  1.2594e+00],\n",
       "             [ 1.3184e+00,  1.2398e+00,  1.2988e+00,  ...,  1.2201e+00,\n",
       "               1.2594e+00,  1.2201e+00]],\n",
       "   \n",
       "            [[ 1.1984e-01,  2.7802e-03, -1.5330e-01,  ..., -1.5776e+00,\n",
       "              -1.3434e+00, -1.2264e+00],\n",
       "             [-1.3379e-01, -5.0449e-01, -9.1420e-01,  ..., -1.5971e+00,\n",
       "              -1.4215e+00, -1.2069e+00],\n",
       "             [-7.3861e-01, -1.2849e+00, -1.5580e+00,  ..., -1.4995e+00,\n",
       "              -1.4215e+00, -1.1288e+00],\n",
       "             ...,\n",
       "             [ 1.5441e+00,  1.5441e+00,  1.5246e+00,  ...,  1.5636e+00,\n",
       "               1.5246e+00,  1.5051e+00],\n",
       "             [ 1.4661e+00,  1.3880e+00,  1.3685e+00,  ...,  1.4270e+00,\n",
       "               1.4270e+00,  1.4270e+00],\n",
       "             [ 1.4856e+00,  1.4075e+00,  1.4661e+00,  ...,  1.3880e+00,\n",
       "               1.4270e+00,  1.3880e+00]]],\n",
       "   \n",
       "   \n",
       "           ...,\n",
       "   \n",
       "   \n",
       "           [[[-1.6537e+00, -1.3047e+00, -7.8135e-01,  ..., -1.9832e+00,\n",
       "              -2.2546e+00, -2.1964e+00],\n",
       "             [-8.7827e-01, -5.8750e-01, -6.0688e-01,  ..., -1.9057e+00,\n",
       "              -2.0995e+00, -2.0608e+00],\n",
       "             [-1.2854e+00, -1.0915e+00, -1.3241e+00,  ..., -1.9251e+00,\n",
       "              -2.1383e+00, -2.0801e+00],\n",
       "             ...,\n",
       "             [-1.1303e+00, -1.0915e+00, -8.5889e-01,  ..., -4.3242e-01,\n",
       "              -8.0073e-01, -8.7827e-01],\n",
       "             [-1.3823e+00, -1.1884e+00, -1.0140e+00,  ..., -7.6196e-01,\n",
       "              -9.5581e-01, -8.0073e-01],\n",
       "             [-1.6537e+00, -1.4404e+00, -1.2854e+00,  ..., -6.6504e-01,\n",
       "              -1.0334e+00, -7.6196e-01]],\n",
       "   \n",
       "            [[-2.4183e+00, -2.3986e+00, -2.2413e+00,  ..., -2.2216e+00,\n",
       "              -2.4183e+00, -2.4183e+00],\n",
       "             [-2.4183e+00, -2.4183e+00, -1.9856e+00,  ..., -2.1823e+00,\n",
       "              -2.3593e+00, -2.3396e+00],\n",
       "             [-2.4183e+00, -2.4183e+00, -1.8282e+00,  ..., -2.2413e+00,\n",
       "              -2.4183e+00, -2.4183e+00],\n",
       "             ...,\n",
       "             [-1.9659e+00, -1.8873e+00, -1.7102e+00,  ..., -1.5136e+00,\n",
       "              -1.7692e+00, -1.7102e+00],\n",
       "             [-2.2216e+00, -1.9856e+00, -1.8086e+00,  ..., -1.7692e+00,\n",
       "              -1.8086e+00, -1.6316e+00],\n",
       "             [-2.4183e+00, -2.2413e+00, -2.0446e+00,  ..., -1.6316e+00,\n",
       "              -1.7889e+00, -1.6119e+00]],\n",
       "   \n",
       "            [[-2.2214e+00, -2.1043e+00, -1.8702e+00,  ..., -1.9678e+00,\n",
       "              -2.2214e+00, -2.1629e+00],\n",
       "             [-2.2214e+00, -1.9678e+00, -1.6166e+00,  ..., -1.9287e+00,\n",
       "              -2.0653e+00, -2.0458e+00],\n",
       "             [-2.2214e+00, -2.1238e+00, -1.5385e+00,  ..., -1.9287e+00,\n",
       "              -2.1434e+00, -2.1238e+00],\n",
       "             ...,\n",
       "             [-1.6751e+00, -1.5776e+00, -1.3629e+00,  ..., -1.1678e+00,\n",
       "              -1.4215e+00, -1.4215e+00],\n",
       "             [-1.9287e+00, -1.6751e+00, -1.4605e+00,  ..., -1.4215e+00,\n",
       "              -1.4605e+00, -1.3434e+00],\n",
       "             [-2.2019e+00, -1.9287e+00, -1.7531e+00,  ..., -1.2654e+00,\n",
       "              -1.4605e+00, -1.2654e+00]]],\n",
       "   \n",
       "   \n",
       "           [[[-5.0996e-01, -7.8135e-01, -8.2012e-01,  ..., -8.3491e-02,\n",
       "              -1.6103e-01, -1.8042e-01],\n",
       "             [-5.0996e-01, -8.3950e-01, -8.0073e-01,  ..., -6.4106e-02,\n",
       "              -1.2226e-01, -1.8042e-01],\n",
       "             [-6.6504e-01, -1.0721e+00, -5.8750e-01,  ..., -4.3242e-01,\n",
       "              -4.5180e-01, -4.7119e-01],\n",
       "             ...,\n",
       "             [ 4.2052e-01,  4.2052e-01,  4.2052e-01,  ...,  4.2052e-01,\n",
       "               3.4298e-01,  4.0113e-01],\n",
       "             [ 4.3990e-01,  4.2052e-01,  4.0113e-01,  ...,  4.3990e-01,\n",
       "               4.3990e-01,  4.3990e-01],\n",
       "             [ 4.7867e-01,  4.5929e-01,  4.3990e-01,  ...,  4.7867e-01,\n",
       "               4.3990e-01,  4.5929e-01]],\n",
       "   \n",
       "            [[-5.4990e-01, -8.0557e-01, -9.2357e-01,  ..., -3.8567e-02,\n",
       "              -1.1723e-01, -1.5657e-01],\n",
       "             [-5.6957e-01, -8.8424e-01, -9.2357e-01,  ..., -3.8567e-02,\n",
       "              -9.7567e-02, -1.5657e-01],\n",
       "             [-7.0724e-01, -1.1202e+00, -6.8757e-01,  ..., -4.7124e-01,\n",
       "              -5.3024e-01, -5.4990e-01],\n",
       "             ...,\n",
       "             [ 4.7277e-01,  4.7277e-01,  4.7277e-01,  ...,  4.7277e-01,\n",
       "               3.9410e-01,  4.7277e-01],\n",
       "             [ 4.9244e-01,  4.7277e-01,  4.5310e-01,  ...,  4.9244e-01,\n",
       "               4.9244e-01,  4.9244e-01],\n",
       "             [ 5.3177e-01,  5.1211e-01,  4.9244e-01,  ...,  5.3177e-01,\n",
       "               4.9244e-01,  5.1211e-01]],\n",
       "   \n",
       "            [[-4.6547e-01, -8.3616e-01, -1.0118e+00,  ...,  1.3935e-01,\n",
       "               2.2291e-02,  2.2291e-02],\n",
       "             [-5.0449e-01, -9.1420e-01, -1.0508e+00,  ...,  8.0821e-02,\n",
       "               2.7802e-03, -5.5751e-02],\n",
       "             [-6.9959e-01, -1.2069e+00, -8.7518e-01,  ..., -4.6547e-01,\n",
       "              -5.0449e-01, -5.0449e-01],\n",
       "             ...,\n",
       "             [ 6.4662e-01,  6.4662e-01,  6.4662e-01,  ...,  6.4662e-01,\n",
       "               5.6858e-01,  6.4662e-01],\n",
       "             [ 6.6613e-01,  6.4662e-01,  6.2711e-01,  ...,  6.6613e-01,\n",
       "               6.6613e-01,  6.6613e-01],\n",
       "             [ 7.0515e-01,  6.8564e-01,  6.6613e-01,  ...,  7.0515e-01,\n",
       "               6.6613e-01,  6.8564e-01]]],\n",
       "   \n",
       "   \n",
       "           [[[-8.3491e-02, -8.3491e-02, -8.3491e-02,  ..., -7.4258e-01,\n",
       "              -8.3950e-01, -8.7827e-01],\n",
       "             [-8.3491e-02, -8.3491e-02, -8.3491e-02,  ..., -8.5889e-01,\n",
       "              -1.0721e+00, -9.7520e-01],\n",
       "             [-8.3491e-02, -8.3491e-02, -8.3491e-02,  ..., -8.7827e-01,\n",
       "              -1.0527e+00, -9.7520e-01],\n",
       "             ...,\n",
       "             [ 5.7560e-01,  6.1437e-01,  6.7252e-01,  ...,  2.4605e-01,\n",
       "              -4.3242e-01, -7.6196e-01],\n",
       "             [ 5.9498e-01,  5.5621e-01,  6.5314e-01,  ..., -3.5488e-01,\n",
       "              -8.3950e-01, -4.9057e-01],\n",
       "             [ 5.9498e-01,  4.7867e-01,  4.7867e-01,  ...,  7.1589e-02,\n",
       "               3.4298e-01,  6.1437e-01]],\n",
       "   \n",
       "            [[ 7.9434e-02,  7.9434e-02,  7.9434e-02,  ..., -5.8924e-01,\n",
       "              -7.4657e-01, -7.8591e-01],\n",
       "             [ 7.9434e-02,  7.9434e-02,  7.9434e-02,  ..., -8.0557e-01,\n",
       "              -9.8258e-01, -9.2357e-01],\n",
       "             [ 7.9434e-02,  9.9101e-02,  7.9434e-02,  ..., -8.0557e-01,\n",
       "              -9.8258e-01, -9.0391e-01],\n",
       "             ...,\n",
       "             [ 2.1710e-01,  2.5644e-01,  3.1544e-01,  ..., -1.5657e-01,\n",
       "              -6.6791e-01, -9.2357e-01],\n",
       "             [ 2.7610e-01,  2.7610e-01,  3.1544e-01,  ..., -6.2857e-01,\n",
       "              -1.0219e+00, -7.0724e-01],\n",
       "             [ 2.9577e-01,  2.1710e-01,  2.3677e-01,  ..., -2.3524e-01,\n",
       "               7.6703e-04,  2.7610e-01]],\n",
       "   \n",
       "            [[ 8.2221e-01,  8.2221e-01,  8.2221e-01,  ..., -5.2400e-01,\n",
       "              -8.3616e-01, -7.9714e-01],\n",
       "             [ 8.4172e-01,  8.2221e-01,  8.2221e-01,  ..., -1.1093e+00,\n",
       "              -1.1873e+00, -8.7518e-01],\n",
       "             [ 8.6123e-01,  8.4172e-01,  8.4172e-01,  ..., -1.1873e+00,\n",
       "              -1.1873e+00, -7.9714e-01],\n",
       "             ...,\n",
       "             [-6.8008e-01, -6.6057e-01, -6.0204e-01,  ..., -9.7273e-01,\n",
       "              -1.0898e+00, -1.1873e+00],\n",
       "             [-5.8253e-01, -5.6302e-01, -5.8253e-01,  ..., -1.2264e+00,\n",
       "              -1.2849e+00, -1.1678e+00],\n",
       "             [-5.0449e-01, -4.8498e-01, -4.6547e-01,  ..., -9.9224e-01,\n",
       "              -8.5567e-01, -6.0204e-01]]]])],\n",
       "  tensor([3, 1, 3, 3, 2, 0, 3, 3, 3, 0, 3, 2, 2, 1, 2, 1, 0, 1, 1, 3, 3, 2, 2, 3,\n",
       "          1, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "          3, 0, 0, 0, 2, 0, 3, 3, 2, 2, 2, 1, 2, 1, 0, 1, 2, 2, 2, 1, 2, 0, 0, 3,\n",
       "          2, 1, 2, 3, 3, 1, 2, 2, 3, 1, 2, 3, 3, 3, 0, 2, 3, 3, 2, 1, 0, 0, 0, 1,\n",
       "          3, 0, 1, 2, 0, 2, 3, 1, 3, 0, 2, 0, 0, 1, 3, 0, 1, 3, 1, 0, 0, 2, 1, 0,\n",
       "          0, 1, 1, 3, 0, 1, 1, 0, 1, 3, 3, 3, 2, 0, 3, 2, 3, 0, 2, 3, 1, 2, 3, 0,\n",
       "          0, 1, 0, 2, 3, 0, 2, 1, 3, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 0, 0, 1, 3, 2,\n",
       "          2, 0, 1, 3, 2, 0, 2, 3, 1, 3, 0, 3, 2, 1, 0, 3, 2, 0, 1, 1, 0, 1, 2, 0,\n",
       "          0, 1, 2, 0, 3, 3, 3, 0, 3, 3, 2, 1, 3, 3, 0, 2, 1, 2, 0, 1, 3, 2, 3, 0,\n",
       "          0, 0, 2, 2, 0, 1, 1, 3, 2, 2, 0, 0, 0, 1, 1, 1, 3, 1, 0, 3, 0, 3, 2, 0,\n",
       "          1, 3, 1, 1, 3, 3, 3, 2, 3, 2, 1, 1, 1, 0, 2, 1])])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "# SplitBatchNorm: simulate multi-gpu behavior of BatchNorm in one gpu by splitting alone the batch dimension\n",
    "# implementation adapted from https://github.com/davidcpage/cifar10-fast/blob/master/torch_backend.py\n",
    "class SplitBatchNorm(torch.nn.BatchNorm2d):\n",
    "    def __init__(self, num_features, num_splits, **kw):\n",
    "        super().__init__(num_features, **kw)\n",
    "        self.num_splits = num_splits\n",
    "\n",
    "    def forward(self, input):\n",
    "        N, C, H, W = input.shape\n",
    "        if self.training or not self.track_running_stats:\n",
    "            running_mean_split = self.running_mean.repeat(self.num_splits)\n",
    "            running_var_split = self.running_var.repeat(self.num_splits)\n",
    "            outcome = torch.nn.functional.batch_norm(\n",
    "                input.view(-1, C * self.num_splits, H, W),\n",
    "                running_mean_split,\n",
    "                running_var_split,\n",
    "                self.weight.repeat(self.num_splits),\n",
    "                self.bias.repeat(self.num_splits),\n",
    "                True,\n",
    "                self.momentum,\n",
    "                self.eps,\n",
    "            ).view(N, C, H, W)\n",
    "            self.running_mean.data.copy_(\n",
    "                running_mean_split.view(self.num_splits, C).mean(dim=0)\n",
    "            )\n",
    "            self.running_var.data.copy_(\n",
    "                running_var_split.view(self.num_splits, C).mean(dim=0)\n",
    "            )\n",
    "            return outcome\n",
    "        else:\n",
    "            return torch.nn.functional.batch_norm(\n",
    "                input,\n",
    "                self.running_mean,\n",
    "                self.running_var,\n",
    "                self.weight,\n",
    "                self.bias,\n",
    "                False,\n",
    "                self.momentum,\n",
    "                self.eps,\n",
    "            )\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "class ModelBase(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Common CIFAR ResNet recipe.\n",
    "    Comparing with ImageNet ResNet recipe, it:\n",
    "    (i) replaces conv1 with kernel=3, str=1\n",
    "    (ii) removes pool1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_dim=128, arch=\"resnet18\", bn_splits=8):\n",
    "        super(ModelBase, self).__init__()\n",
    "\n",
    "        # use split batchnorm\n",
    "        norm_layer = (\n",
    "            partial(SplitBatchNorm, num_splits=bn_splits)\n",
    "            if bn_splits > 1\n",
    "            else torch.nn.BatchNorm2d\n",
    "        )\n",
    "        resnet_arch = getattr(resnet, arch)\n",
    "        net = resnet_arch(num_classes=feature_dim, norm_layer=norm_layer)\n",
    "\n",
    "        self.net = []\n",
    "        for name, module in net.named_children():\n",
    "            if name == \"conv1\":\n",
    "                module = torch.nn.Conv2d(\n",
    "                    3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "                )\n",
    "            if isinstance(module, torch.nn.MaxPool2d):\n",
    "                continue\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                self.net.append(torch.nn.Flatten(1))\n",
    "            self.net.append(module)\n",
    "\n",
    "        self.net = torch.nn.Sequential(*self.net)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        # note: not normalized here\n",
    "        return x\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "def copy_params(encQ, encK, m=None):\n",
    "    if m is None:\n",
    "        for param_q, param_k in zip(encQ.parameters(), encK.parameters()):\n",
    "            param_k.data.copy_(param_q.data)  # initialize\n",
    "            param_k.requires_grad = False  # not update by gradient\n",
    "    else:\n",
    "        for param_q, param_k in zip(encQ.parameters(), encK.parameters()):\n",
    "            param_k.data = param_k.data * m + param_q.data * (1.0 - m)\n",
    "\n",
    "\n",
    "def create_encoder():\n",
    "    model = ModelBase()\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "# test using a knn monitor\n",
    "def test(net, memory_data_loader, test_data_loader, epoch, knn_k, knn_t, record_keeper):\n",
    "    net.eval()\n",
    "    classes = len(memory_data_loader.dataset.classes)\n",
    "    total_top1, total_num, feature_bank = 0.0, 0, []\n",
    "    with torch.no_grad():\n",
    "        # generate feature bank\n",
    "        for data, target in tqdm(memory_data_loader, desc=\"Feature extracting\"):\n",
    "            feature = net(data.cuda(non_blocking=True))\n",
    "            feature = torch.nn.functional.normalize(feature, dim=1)\n",
    "            feature_bank.append(feature)\n",
    "        # [D, N]\n",
    "        feature_bank = torch.cat(feature_bank, dim=0).t().contiguous()\n",
    "        # [N]\n",
    "        feature_labels = torch.tensor(\n",
    "            memory_data_loader.dataset.targets, device=feature_bank.device\n",
    "        )\n",
    "        # loop test data to predict the label by weighted knn search\n",
    "        test_bar = tqdm(test_data_loader)\n",
    "        for data, target in test_bar:\n",
    "            data, target = data.cuda(non_blocking=True), target.cuda(non_blocking=True)\n",
    "            feature = net(data)\n",
    "            feature = torch.nn.functional.normalize(feature, dim=1)\n",
    "\n",
    "            pred_labels = knn_predict(\n",
    "                feature, feature_bank, feature_labels, classes, knn_k, knn_t\n",
    "            )\n",
    "\n",
    "            total_num += data.size(0)\n",
    "            total_top1 += (pred_labels[:, 0] == target).float().sum().item()\n",
    "            acc = total_top1 / total_num * 100\n",
    "            test_bar.set_description(\"Test Epoch {}: Acc@1:{:.2f}%\".format(epoch, acc))\n",
    "\n",
    "    record_keeper.update_records(\n",
    "        {\"knn_monitor_accuracy\": acc},\n",
    "        epoch,\n",
    "        parent_name=\"accuracy\",\n",
    "    )\n",
    "    record_keeper.save_records()\n",
    "    return acc\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "# knn monitor as in InstDisc https://arxiv.org/abs/1805.01978\n",
    "# implementation follows http://github.com/zhirongw/lemniscate.pytorch and https://github.com/leftthomas/SimCLR\n",
    "def knn_predict(feature, feature_bank, feature_labels, classes, knn_k, knn_t):\n",
    "    # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    sim_matrix = torch.mm(feature, feature_bank)\n",
    "    # [B, K]\n",
    "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
    "    # [B, K]\n",
    "    sim_labels = torch.gather(\n",
    "        feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices\n",
    "    )\n",
    "    sim_weight = (sim_weight / knn_t).exp()\n",
    "\n",
    "    # counts for each class\n",
    "    one_hot_label = torch.zeros(\n",
    "        feature.size(0) * knn_k, classes, device=sim_labels.device\n",
    "    )\n",
    "    # [B*K, C]\n",
    "    one_hot_label = one_hot_label.scatter(\n",
    "        dim=-1, index=sim_labels.view(-1, 1), value=1.0\n",
    "    )\n",
    "    # weighted score ---> [B, C]\n",
    "    pred_scores = torch.sum(\n",
    "        one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1),\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "    return pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_records(loss, loss_fn, optimizer, record_keeper, global_iteration):\n",
    "    def optimizer_custom_attr_func(opt):\n",
    "        return {\"lr\": opt.param_groups[0][\"lr\"]}\n",
    "\n",
    "    record_these = [\n",
    "        [{\"loss\": loss.item()}, {\"parent_name\": \"loss_histories\"}],\n",
    "        [{\"loss_function\": loss_fn}, {\"recursive_types\": [torch.nn.Module]}],\n",
    "        [{\"optimizer\": optimizer}, {\"custom_attr_func\": optimizer_custom_attr_func}],\n",
    "    ]\n",
    "    for record, kwargs in record_these:\n",
    "        record_keeper.update_records(record, global_iteration, **kwargs)\n",
    "\n",
    "\n",
    "def save_model(encQ):\n",
    "    model_folder = \"example_saved_models\"\n",
    "    if not os.path.exists(model_folder):\n",
    "        os.makedirs(model_folder)\n",
    "    torch.save(encQ.state_dict(), \"{}/encQ_best.pth\".format(model_folder))\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "def batch_shuffle_single_gpu(x):\n",
    "    \"\"\"\n",
    "    Batch shuffle, for making use of BatchNorm.\n",
    "    \"\"\"\n",
    "    # random shuffle index\n",
    "    idx_shuffle = torch.randperm(x.shape[0]).cuda()\n",
    "\n",
    "    # index for restoring\n",
    "    idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "    return x[idx_shuffle], idx_unshuffle\n",
    "\n",
    "\n",
    "######################\n",
    "### from MoCo repo ###\n",
    "######################\n",
    "def batch_unshuffle_single_gpu(x, idx_unshuffle):\n",
    "    \"\"\"\n",
    "    Undo batch shuffle.\n",
    "    \"\"\"\n",
    "    return x[idx_unshuffle]\n",
    "\n",
    "\n",
    "def create_labels(num_pos_pairs, previous_max_label):\n",
    "    # create labels that indicate what the positive pairs are\n",
    "    labels = torch.arange(0, num_pos_pairs)\n",
    "    labels = torch.cat((labels, labels)).to(device)\n",
    "    # add an offset so that the labels do not overlap with any labels in the memory queue\n",
    "    labels += previous_max_label + 1\n",
    "    # we want to enqueue the output of encK, which is the 2nd half of the batch\n",
    "    enqueue_mask = torch.zeros(len(labels)).bool()\n",
    "    enqueue_mask[num_pos_pairs:] = True\n",
    "    return labels, enqueue_mask\n",
    "\n",
    "\n",
    "def train(\n",
    "    encQ,\n",
    "    encK,\n",
    "    paramK_momentum,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    record_keeper,\n",
    "    global_iteration,\n",
    "):\n",
    "    encQ.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    for images, _ in pbar:\n",
    "        previous_max_label = torch.max(loss_fn.label_memory)\n",
    "        imgQ = images[0].to(device)\n",
    "        imgK = images[1].to(device)\n",
    "\n",
    "        # compute output\n",
    "        encQ_out = encQ(imgQ)\n",
    "        with torch.no_grad():  # no gradient to keys\n",
    "            copy_params(encQ, encK, m=paramK_momentum)\n",
    "            imgK, idx_unshuffle = batch_shuffle_single_gpu(imgK)\n",
    "            encK_out = encK(imgK)\n",
    "            encK_out = batch_unshuffle_single_gpu(encK_out, idx_unshuffle)\n",
    "\n",
    "        all_enc = torch.cat([encQ_out, encK_out], dim=0)\n",
    "        labels, enqueue_mask = create_labels(encQ_out.size(0), previous_max_label)\n",
    "        loss = loss_fn(all_enc, labels, enqueue_mask=enqueue_mask)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pbar.set_description(\"loss=%.5f\" % loss.item())\n",
    "        update_records(\n",
    "            loss, loss_fn, optimizer, record_keeper, global_iteration[\"iter\"]\n",
    "        )\n",
    "        global_iteration[\"iter\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'example_logs/logs.db'\n",
      "removed 'example_logs/accuracy.csv'\n",
      "removed directory 'example_logs'\n",
      "removed 'example_tensorboard/events.out.tfevents.1711715724.aarya-ExcaliburOMEN.7601.1'\n",
      "removed directory 'example_tensorboard'\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8071), started 1:31:14 ago. (Use '!kill 8071' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3d2a39dca92b71a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3d2a39dca92b71a\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -rfv example_logs example_tensorboard example_saved_models\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir example_tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting epoch 1\n",
      "loss=7.65001:  83%| | 10/12 [00:04<00:00,  2.92it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7aa7e3f2b5e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aarya/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/aarya/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/aarya/miniconda3/envs/pyTorch/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "loss=7.65001:  83%| | 10/12 [00:04<00:00,  2.15it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 19820) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 19820) is killed by signal: Aborted. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     48\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m---> 49\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencQ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparamK_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrecord_keeper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# curr_accuracy = test(\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m#     encQ, train_loader_for_eval, val_loader, epoch, knn_k, knn_t, record_keeper\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m#     save_model(encQ)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[98], line 71\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(encQ, encK, paramK_momentum, loss_fn, optimizer, train_loader, record_keeper, global_iteration)\u001b[0m\n\u001b[1;32m     69\u001b[0m encQ\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     70\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader)\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m     72\u001b[0m     previous_max_label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(loss_fn\u001b[38;5;241m.\u001b[39mlabel_memory)\n\u001b[1;32m     73\u001b[0m     imgQ \u001b[38;5;241m=\u001b[39m images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/pyTorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1145\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1144\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 19820) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "lr = 0.03\n",
    "paramK_momentum = 0.99\n",
    "memory_size = 4096\n",
    "num_epochs = 200\n",
    "knn_k = 200\n",
    "knn_t = 0.1\n",
    "\n",
    "(\n",
    "    train_dataset,\n",
    "    train_dataset_for_eval,\n",
    "    val_dataset,\n",
    "    train_loader,\n",
    "    train_loader_for_eval,\n",
    "    val_loader,\n",
    ") = create_dataset(batch_size)\n",
    "\n",
    "encQ = create_encoder()\n",
    "encK = create_encoder()\n",
    "\n",
    "# copy params from encQ into encK\n",
    "copy_params(encQ, encK)\n",
    "\n",
    "optimizer = torch.optim.SGD(encQ.parameters(), lr, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "\n",
    "###########################################################\n",
    "### Set the loss function and the (optional) miner here ###\n",
    "###########################################################\n",
    "loss_fn = losses.CrossBatchMemory(\n",
    "    loss=losses.NTXentLoss(temperature=0.1), embedding_size=128, memory_size=memory_size\n",
    ")\n",
    "\n",
    "dataset_dict = {\"train\": train_dataset_for_eval, \"val\": val_dataset}\n",
    "record_keeper, _, _ = logging_presets.get_record_keeper(\n",
    "    \"example_logs\", \"example_tensorboard\"\n",
    ")\n",
    "hooks = logging_presets.get_hook_container(record_keeper)\n",
    "\n",
    "# # first check untrained performance\n",
    "# epoch = 0\n",
    "# best_accuracy = test(\n",
    "#     encQ, train_loader_for_eval, val_loader, epoch, knn_k, knn_t, record_keeper\n",
    "# )\n",
    "\n",
    "global_iteration = {\"iter\": 0}\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    logging.info(\"Starting epoch {}\".format(epoch))\n",
    "    train(\n",
    "        encQ,\n",
    "        encK,\n",
    "        paramK_momentum,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        record_keeper,\n",
    "        global_iteration,\n",
    "    )\n",
    "    # curr_accuracy = test(\n",
    "    #     encQ, train_loader_for_eval, val_loader, epoch, knn_k, knn_t, record_keeper\n",
    "    # )\n",
    "    # if curr_accuracy > best_accuracy:\n",
    "    #     best_accuracy = curr_accuracy\n",
    "    #     save_model(encQ)\n",
    "    # scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
