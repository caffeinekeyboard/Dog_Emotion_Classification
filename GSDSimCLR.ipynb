{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of SimCLR framework to carry out emotion classification on German Shepherds\n",
    "- Date : February 17th 2024\n",
    "- Author : Aarya Bhave\n",
    "- Project : Dog_Emotion_Classification\n",
    "  \n",
    "This code implements the SimCLR framework to carry out self-supervised contrastive leanrning to detect emotions in German Shepherds.  \n",
    "Currently Limited to German Shepherds only.  \n",
    "PyTorch version '2.1.1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil, time, os, tqdm, requests, random, copy\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed = 16):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up the DataSet class.\n",
    "- 264 unlabeled images of German Shepherds.\n",
    "- Processor threading based augmentation techniques for low latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "\n",
    "class GSDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transforms = None):\n",
    "        self.root_dir = 'data/processed/YOLOCrops/German_Shepherd/dog'\n",
    "        self.image_paths = list(paths.list_images(self.root_dir))\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = Image.open(self.image_paths[index])\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up the Data Transformations.\n",
    "- MUST BE TINKERED WITH.\n",
    "- Data augmentations are treated as hyper-parameters.\n",
    "- Images will be resized to 224, 224.\n",
    "- 18FEB2024 - Random Resize and Crop, Random Horizontal Flip, Random Color Jitters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augment:\n",
    "    def __call__(self, sample):\n",
    "        my_transforms = transforms.Compose([transforms.RandomResizedCrop((224, 224), scale = (0.75, 1)),\n",
    "                                         transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                         transforms.ColorJitter(brightness=(0.80,1.20),contrast=(0.75, 1.25),saturation=(0.75,1.25),hue=(-0.1,0.1))])\n",
    "        sample = my_transforms(sample)\n",
    "        return sample\n",
    "    \n",
    "augmentations = transforms.Compose([Augment(), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up hyper-parameters.\n",
    "- Epochs ~600.\n",
    "- Batch Size ~256.\n",
    "- Temperature ~0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up the DataLoaders\n",
    "- Issue : shuffle=True causes len() arguement to breakdown. !Fixed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GSDDataset(transforms=augmentations)\n",
    "dataloader = DataLoader(dataset = dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(dataloader)\n",
    "data = next(dataiter)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model\n",
    "- Encoder -> Projection Head -> NT Xent Loss.\n",
    "- Encoder ~ResNet50 18FEB2024\n",
    "- Projection Head ~MultiLayerPerceptron with one hidden layer 18FEB2024\n",
    "- NT Xent Loss Temperature ~0.2 18FEB2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 use_bias = True,\n",
    "                 use_bn = False,\n",
    "                 **kwargs):\n",
    "        super(LinearLayer, self).__init__(**kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.use_bias = use_bias\n",
    "        self.use_bn = use_bn\n",
    "\n",
    "        self.linear = nn.Linear(self.in_features, self.out_features, bias=self.use_bias and not self.use_bn)\n",
    "\n",
    "        if self.use_bn:\n",
    "            self.bn = nn.BatchNorm1d(self.out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "        return x\n",
    "    \n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_features,\n",
    "                 out_features,\n",
    "                 head_type = 'nonlinear',\n",
    "                 **kwargs):\n",
    "        super(ProjectionHead, self).__init__(**kwargs)\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.head_type = head_type\n",
    "\n",
    "        if self.head_type == 'linear':\n",
    "            self.layers = LinearLayer(self.in_features, self.out_features, False, True)\n",
    "        elif self.head_type =='nonlinear':\n",
    "            self.layers = nn.Sequential(LinearLayer(self.in_features, self.hidden_features, True, True),\n",
    "                                        nn.ReLU(),\n",
    "                                        LinearLayer(self.hidden_features, self.out_features, False, True))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "class PreModel(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "\n",
    "        #PRETRAINED MODEL\n",
    "        self.pretrained = models.resnet50(pretrained = True)\n",
    "\n",
    "        self.pretrained.conv1 = nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
    "        self.pretrained.maxpool = Identity()\n",
    "\n",
    "        self.pretrained.fc = Identity()\n",
    "\n",
    "        for p in self.pretrained.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        self.projector = ProjectionHead(2048, 2048, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pretrained(x)\n",
    "        xp = self.projector(torch.squeeze(out))\n",
    "        return xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
